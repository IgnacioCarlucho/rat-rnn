{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rat RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "from unityagents import UnityEnvironment\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "weights_regularization = 0.2\n",
    "act_regularization = 0.2\n",
    "hidden_units = 128\n",
    "train_steps = 10000\n",
    "ep_length = 500\n",
    "sim_steps = 1000000\n",
    "batch_size = 512\n",
    "\n",
    "tau = 10.0\n",
    "noise_stddev = 0.5\n",
    "zero_speed_probability = 0.5\n",
    "\n",
    "# [rotation.y, velocity.x, velocity.z, angularVelocity.y, velocity.magnitude, heading, velocity]\n",
    "x_components = [0, 4]\n",
    "\n",
    "unity_params = {\n",
    "    'start_area_extents': 8.0,\n",
    "    'ep_length': ep_length}\n",
    "\n",
    "model_path = 'rat_model_rnn'\n",
    "data_path = 'rat_data_large_rnd'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data\n",
    "Prerequisite: Load unity project in the Editor. Build and save executable as \"rat.exe\" or \"rat.app\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env_name = \"rat\" # Name of the Unity environment binary to launch\n",
    "env = UnityEnvironment(file_name=env_name, worker_id=1)\n",
    "\n",
    "# Examine environment parameters\n",
    "print(str(env))\n",
    "\n",
    "# Set the default brain to work with\n",
    "default_brain = env.brain_names[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,z,ep = [], [], []\n",
    "input_x = []\n",
    "a = env.reset(config=unity_params)[default_brain]\n",
    "for i in range(sim_steps - 1):\n",
    "    \n",
    "    # check for NANs\n",
    "    if a.states[0].dtype != np.float64:\n",
    "        print(i, a.states[0].dtype, a.states[0])\n",
    "    elif np.any(np.isnan(a.states[0])):\n",
    "        print(i, \"NAN\", a.states[0])\n",
    "        \n",
    "    # append\n",
    "    x.append(a.states[0][0])\n",
    "    z.append(a.states[0][1])\n",
    "    input_x.append(a.states[0][2:-1])\n",
    "    ep.append(a.states[0][-1])\n",
    "\n",
    "    # next simulation step\n",
    "    a = env.step()[default_brain]\n",
    "\n",
    "    if i % (sim_steps/10) == 0 and i != 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.array(x)\n",
    "z = np.array(z)\n",
    "input_x = np.array(input_x)\n",
    "input_y = np.stack((x, z), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(data_path)\n",
    "\n",
    "save_data = {\"x\": input_x, \"y\": input_y}\n",
    "pickle.dump(save_data, open(data_path+\"/data.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_data = pickle.load(open(data_path+\"/data.p\", \"rb\"))\n",
    "input_x = save_data[\"x\"]\n",
    "input_y = save_data[\"y\"]\n",
    "x = input_y[:, 0]\n",
    "z = input_y[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [rotation.y, velocity.x, velocity.z, angularVelocity.y, velocity.magnitude, heading, velocity]\n",
    "print(np.shape(input_x))\n",
    "input_x = input_x[:, x_components] # rotation and velocity\n",
    "input_x[:,-1] /= np.max(abs(input_x[:,-1]))\n",
    "print(np.shape(input_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(input_x[:,0]), np.max(input_x[:,0]))\n",
    "print(np.min(input_x[:,1]), np.max(input_x[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(np.abs(input_y[:, 0])), np.max(np.abs(input_y[:, 1])))\n",
    "input_y[:, 0] /= np.max(np.abs(input_y[:, 0]))\n",
    "input_y[:, 1] /= np.max(np.abs(input_y[:, 1]))\n",
    "x = input_y[:, 0]\n",
    "z = input_y[:, 1]\n",
    "\n",
    "maze_extents = np.max(np.abs(input_y[:, :]))\n",
    "maze_extents *= 1.125 # plus 12% for borders\n",
    "\n",
    "print(maze_extents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Rat Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_colors(length, segments):\n",
    "    c_list = []\n",
    "    for i in range(segments):\n",
    "        color = np.zeros([length//segments, 4])\n",
    "        color[:, 3] = 0.5\n",
    "        color[:, 0:3] = np.random.uniform(0, 1, size=[1, 3])\n",
    "        c_list.append(color)\n",
    "    c_list = np.reshape(c_list, [length, 4])\n",
    "    return c_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "plt.scatter(x, z, s=1, c=create_colors(sim_steps, sim_steps//ep_length))\n",
    "plt.ylim(-maze_extents, maze_extents)\n",
    "plt.xlim(-maze_extents, maze_extents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "for i in range(15):\n",
    "    pointer = i\n",
    "    batch_y = input_y[pointer*ep_length:(pointer+1)*ep_length]\n",
    "    \n",
    "    plt.subplot(3, 5, 1 + i)\n",
    "    plt.scatter(batch_y[:,0], batch_y[:, 1], s=1, c=[0,1,0,1])\n",
    "    plt.ylim(-maze_extents, maze_extents)\n",
    "    plt.xlim(-maze_extents, maze_extents)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rat RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyBasicLSTMCell(tf.contrib.rnn.RNNCell):\n",
    "  def __init__(self, num_units, noise_stddev, forget_bias=1.0,\n",
    "               activation=None, reuse=None):\n",
    "    super(MyBasicLSTMCell, self).__init__(_reuse=reuse)\n",
    "    self._num_units = num_units\n",
    "    self._noise_stddev = noise_stddev\n",
    "    self._forget_bias = forget_bias\n",
    "    self._activation = activation or tf.nn.tanh\n",
    "    self._linear = None\n",
    "\n",
    "  @property\n",
    "  def state_size(self):\n",
    "    return (tf.contrib.rnn.LSTMStateTuple(self._num_units, self._num_units))\n",
    "\n",
    "  @property\n",
    "  def output_size(self):\n",
    "    return self._num_units\n",
    "\n",
    "  def call(self, inputs, state):\n",
    "    sigmoid = tf.sigmoid\n",
    "    c, h = state\n",
    "\n",
    "    if self._linear is None:\n",
    "      self._linear = _Linear([inputs, h], 4 * self._num_units, True)\n",
    "    # i = input_gate, j = new_input, f = forget_gate, o = output_gate\n",
    "    i, j, f, o = tf.split(\n",
    "        value=self._linear([inputs, h]), num_or_size_splits=4, axis=1)\n",
    "\n",
    "    new_c = (\n",
    "        c * sigmoid(f + self._forget_bias) + sigmoid(i) * self._activation(j))\n",
    "    new_h = self._activation(new_c) * sigmoid(o)\n",
    "    new_h = tf.add(new_h,\n",
    "                   tf.random_normal(shape=tf.shape(new_h), mean=0.0, stddev=self._noise_stddev, dtype=tf.float32))\n",
    "\n",
    "    new_state = tf.contrib.rnn.LSTMStateTuple(new_c, new_h)\n",
    "    return new_h, new_state\n",
    "\n",
    "\n",
    "from tensorflow.python.ops.rnn_cell_impl import _Linear\n",
    "\n",
    "class MyCTRNNCell(tf.contrib.rnn.RNNCell):\n",
    "  def __init__(self, num_units, tau, noise_stddev, activation=None, reuse=None):\n",
    "    super(MyCTRNNCell, self).__init__(_reuse=reuse)\n",
    "    self._num_units = num_units\n",
    "    self._tau = tau\n",
    "    self._noise_stddev = noise_stddev\n",
    "    self._activation = activation or tf.nn.tanh\n",
    "    self._linear = None\n",
    "\n",
    "  @property\n",
    "  def state_size(self):\n",
    "    return (tf.contrib.rnn.LSTMStateTuple(self._num_units, self._num_units))\n",
    "\n",
    "  @property\n",
    "  def output_size(self):\n",
    "    return self._num_units\n",
    "\n",
    "  def call(self, inputs, state):\n",
    "    \"\"\" Continuous Time RNN:\n",
    "        dx/dt = -x + W * input + U * act(x) + B + noise\n",
    "        x' = x + 1/tau * dx/dt\n",
    "    \"\"\"\n",
    "    \n",
    "    old_x, old_u = state\n",
    "    new_u = self._activation(old_x)\n",
    "    \n",
    "    if self._linear is None:\n",
    "        self._linear = _Linear([inputs, new_u], self._num_units, True)\n",
    "\n",
    "    dxdt = self._linear([inputs, new_u]) - old_x\n",
    "    dxdt = tf.add(dxdt,\n",
    "                   tf.random_normal(shape=tf.shape(dxdt), mean=0.0, stddev=self._noise_stddev, dtype=tf.float32))\n",
    "    new_x = old_x + 1.0/self._tau * dxdt\n",
    "    return new_x, tf.contrib.rnn.LSTMStateTuple(new_x, new_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RatRNN(object):\n",
    "    def __init__(self, x_size, y_size, h_size, batch_size, lr):\n",
    "        self.x = tf.placeholder(shape=[None, x_size], dtype=tf.float32)\n",
    "        self.train_length = tf.placeholder(shape=[1], dtype=tf.int32)\n",
    "        #self.batch_size = tf.placeholder(shape=[1], dtype=tf.int32)\n",
    "        self.noise_stddev = tf.placeholder(shape=[1], dtype=tf.float32)\n",
    "\n",
    "        self.rnn_in = tf.reshape(self.x, shape=[batch_size, self.train_length[0], x_size])\n",
    "\n",
    "        cell = MyCTRNNCell(h_size, tau, self.noise_stddev)\n",
    "        self.state_in = cell.zero_state(batch_size, tf.float32)\n",
    "\n",
    "        self.rnn, self.rnn_state = tf.nn.dynamic_rnn(inputs=self.rnn_in, cell=cell, dtype=tf.float32,\n",
    "                                                     initial_state=self.state_in)\n",
    "        \n",
    "        self.output = tf.reshape(self.rnn, shape=[-1, h_size])  \n",
    "        \n",
    "        self.y_pred = tf.layers.dense(self.output, y_size,\n",
    "                                      kernel_initializer=tf.zeros_initializer(),\n",
    "                                      bias_initializer=tf.zeros_initializer(),\n",
    "                                      activation=None)\n",
    "\n",
    "        self.y = tf.placeholder(shape=[None, y_size], dtype=tf.float32)\n",
    "        \n",
    "        lossL2A = tf.nn.l2_loss(self.output) / float(batch_size * h_size * ep_length)\n",
    "        lossL2W = tf.add_n([ tf.nn.l2_loss(v) for v in tf.trainable_variables() if 'bias' not in v.name ]) / float(h_size)\n",
    "\n",
    "        self.weights_loss = lossL2W * weights_regularization\n",
    "        self.act_loss = lossL2A * act_regularization\n",
    "        self.regress_loss = tf.reduce_sum(tf.squared_difference(self.y, self.y_pred)) / float(batch_size * ep_length)\n",
    "        self.loss = self.regress_loss + self.weights_loss + self.act_loss\n",
    "\n",
    "        self.loss = tf.Print(self.loss, [lossL2A, lossL2W, self.regress_loss])\n",
    "\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "        self.update = optimizer.minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "rat_rnn = RatRNN(len(x_components), 2, hidden_units, batch_size, learning_rate)\n",
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "print(tf.trainable_variables())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "print(ep_length, sim_steps/ep_length)\n",
    "\n",
    "# center training data\n",
    "input_Y = np.copy(input_y)\n",
    "for i in range(sim_steps//ep_length):\n",
    "    pointer = i\n",
    "    input_Y[pointer*ep_length:(pointer+1)*ep_length] -= input_Y[pointer*ep_length]\n",
    "\n",
    "# debug viz\n",
    "plt.figure(figsize=(5,3))\n",
    "for i in range(15):\n",
    "    pointer = i\n",
    "    batch_y = input_Y[pointer*ep_length:(pointer+1)*ep_length]\n",
    "    \n",
    "    plt.subplot(3, 5, 1 + i)\n",
    "    plt.scatter(batch_y[:,0], batch_y[:, 1], s=1, c=[0,1,0,1])\n",
    "    plt.ylim(-maze_extents, maze_extents)\n",
    "    plt.xlim(-maze_extents, maze_extents)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(train_steps):\n",
    "    pointer = np.random.randint(0, sim_steps/ep_length - batch_size)\n",
    "    batch_x = input_x[pointer*ep_length:(pointer+batch_size)*ep_length]\n",
    "    batch_y = input_Y[pointer*ep_length:(pointer+batch_size)*ep_length]\n",
    "    \n",
    "    batch_x[:,-1] *= np.random.choice(a=[0.0, 1.0], size=(len(batch_x[:,-1])),\n",
    "                                      p=[zero_speed_probability, 1-zero_speed_probability])\n",
    "    \n",
    "    feed_dict = {rat_rnn.x: np.reshape(batch_x, [-1,len(x_components)]), rat_rnn.y: np.reshape(batch_y, [-1, 2]), \n",
    "                 rat_rnn.train_length: [ep_length], rat_rnn.noise_stddev: [noise_stddev] }\n",
    "    loss, _ = sess.run([rat_rnn.loss, rat_rnn.update], feed_dict=feed_dict)\n",
    "    if i % 100 == 0 and i != 0:\n",
    "        print(\"Loss: {} -- {}\".format(loss, i//100))\n",
    "    losses.append(loss)\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate *= .5\n",
    "print(learning_rate)\n",
    "train_steps = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Network Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "\n",
    "saver.save(sess, model_path + '/model.cptk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Network Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ckpt = tf.train.get_checkpoint_state(model_path)\n",
    "if ckpt == None:\n",
    "  print('The model {0} could not be found. Make sure you specified the right '\n",
    "    '--run-path'.format(model_path))\n",
    "saver.restore(sess, ckpt.model_checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "for i in range(1):\n",
    "    pointer = i\n",
    "    batch_x = input_x[pointer*ep_length:(pointer+batch_size)*ep_length]\n",
    "    batch_y = input_Y[pointer*ep_length:(pointer+batch_size)*ep_length]\n",
    "\n",
    "    feed_dict = {rat_rnn.x: np.reshape(batch_x, [-1,len(x_components)]), \n",
    "                 rat_rnn.train_length: [ep_length], rat_rnn.noise_stddev: [1*noise_stddev]}\n",
    "    yp = sess.run(rat_rnn.y_pred, feed_dict=feed_dict) + batch_y[0]\n",
    "    \n",
    "for i in range(min(15, batch_size)):\n",
    "    # Real - Green | Predicted - Blue\n",
    "    plt.subplot(3, 5, 1 + i)\n",
    "    a = i*ep_length\n",
    "    b = a+ep_length\n",
    "    plt.scatter(batch_y[a:b,0], batch_y[a:b, 1], s=1, c=[0,1,0,1])\n",
    "    plt.scatter(yp[a:b, 0], yp[a:b, 1], s=1, c=[0,0,1,1])\n",
    "    plt.ylim(-maze_extents, maze_extents)\n",
    "    plt.xlim(-maze_extents, maze_extents)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display neuron activation rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "resolution = 32\n",
    "rate = np.zeros([hidden_units, resolution, resolution])\n",
    "count = np.zeros([resolution, resolution])\n",
    "for i in range(len(input_x)//(ep_length*batch_size)):\n",
    "    pointer = i\n",
    "    batch_x = input_x[pointer*ep_length*batch_size:(pointer+1)*ep_length*batch_size]\n",
    "    batch_y = input_y[pointer*ep_length*batch_size:(pointer+1)*ep_length*batch_size]\n",
    "    feed_dict = {rat_rnn.x: np.reshape(batch_x, [-1,len(x_components)]), \n",
    "                 rat_rnn.train_length: [ep_length], rat_rnn.noise_stddev: [0*noise_stddev]}\n",
    "    act = sess.run(rat_rnn.output, feed_dict=feed_dict)\n",
    "    \n",
    "    for j in range(ep_length*batch_size):\n",
    "        x = (batch_y[j][0] + maze_extents)/(maze_extents*2) * resolution\n",
    "        y = (batch_y[j][1] + maze_extents)/(maze_extents*2) * resolution\n",
    "        count[int(x), int(y)] += 1\n",
    "        rate[:, int(x), int(y)] += np.abs(act[j, :])\n",
    "                      \n",
    "for x in range(resolution):\n",
    "    for y in range(resolution):\n",
    "        if count[x, y] > 0:\n",
    "            rate[:, x, y] /= count[x, y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "            \n",
    "plt.figure(figsize=(15,30))\n",
    "for h in range(hidden_units):\n",
    "    plt.subplot(hidden_units//8, 8, 1 + h)\n",
    "    plt.title('Neuron ' + str(h))\n",
    "    plt.imshow(rate[h,:,:] / np.max(rate[h,:,:]), interpolation=\"nearest\", cmap=\"plasma\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Close TensorFlow Session & Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(input_Y)\n",
    "print(input_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
